# Untitled-cd7a02ef-e5e1-46d0-968a-3e34712e8014

## 深度学习组件模板使用

**深度学习组件模板使用-更新记录**

## **深度学习组件模板使用**

### **深度学习底层平台**

本模块底层使用tensorflow.keras，如使用自定义代码如需import Keras，请用tensorflow.keras。比如

from tensorflow.keras import **backend** as\*\* K from tensorflow.keras import layers

现阶段提供CPU和英伟达GPU独立显卡加速版本镜像，tensorflow版本号为1.13.1。

如需更改镜像请通过如下方式，加上或减去“\_gpu”后缀。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/0cb2165d93183fe94a262bf26a2858a3.png)

修改镜像

目前提供4种镜像供选择。

* dl：Tensorflow CPU
* dl\_gpu：TensorFlow GPU
* dl\_modles：TensorFlow CPU附带打包部分Keras ImageNet 预训练的权值文件。
* dl\_gpu\_models ：TensorFlow GPU附带打包部分Keras ImageNet 预训练的权值文件。

### **快速实例**

#### **Keras CNN手写数字识别**

模板ID：3756

MNIST手写数字图片分类模型，训练一个epoch达到97%的验证数据集准确率。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/8f11be7408030ed7fbc43d4b2390f20c.png)

Keras CNN手写数字识别算盘模板

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/9db3818d12b41aa5325ea94d4211198f.png)

MNIST手写数字数据例子

#### **1添加输入层**

配置模型输入层的名称和shape，shape需要和训练的数据对应。名称可以不填，程序中将会自动通过UUID生成。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/7630d3af9445d52b5d6944f8858f9a15.png)

添加输入层

比如此案例中MNIST数据一张灰度图片为28x28分辨率的。

runtimeCheck如果打钩会在运行当前节点时候尝试连接当前和已知上游网络层，如果有问题将会及时报错。

#### **2创建并连接一个网络层**

下图创建一个2D卷积层，用于在网络中提取图像特征。相关的配置在layerConfig中定义，变量命名与Keras API同步，关于每个参数更多信息请参考[官方文档](https://keras.io/layers/convolutional/#conv2d)。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/03c2b47d49e06f49ce1923d2eee6919f.png)

连接网络层

请按照算盘实例模板拖出、配置、连接其他网络层。

#### **3 创建模型**

在此步骤连接模型的输入、输出。

modelInputStack1对应模型输入层的输出端子。

modelOutpuStack对应模型输出也就是连接最一层的输出端子。

modelConfig参数中可以定义模型变量的名称。如果没有定义程序中会自动生成。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/bbf6030b49590fe5aa86f08860097d7e.png)

创建模型

#### **4加载自带数据集**

在dataset中选择mnist数据集（其他数据集暂不支持）。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/2c832cb3eb9528a78a201b56c98d002b.png)

自带数据集

#### **5 模型训练**

拖出“Keras模型训练”节点，并配置。

此节点内部将会调用Keras model 的compile和fit类函数训练模型并输出.h5格式模型权值文件，右面板中各个配置参数的定义可以参考Keras[官方文档](https://keras.io/models/model/)。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/841c27b4778609d5b2b6062c7e99f476.png)

模型训练

训练进度可以在右面板的执行日志中查看。此节点建议使用GPU镜像运行。切换镜像方法参考上一章节。

#### **5 模型评估和预测**

这两个节点对应Keras model 的[evaluate](https://keras.io/models/model/#evaluate) 和[predict](https://keras.io/models/model/#predict)类函数。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/f530229281a65ff3b8e8f4adbf60d48a.png)

模型评估和预测

模型评估运行完输出的是一个Json类型的数据，包括评估的loss和准确率，比如，

此结果可以在右面板的查看结果中下载

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/ad4d1cac47111302edd6bf894692da7f.png)

查看模型评估和结果

模型预测输出的是个Numpy数据，即[model.predict](https://keras.io/models/model/#predict)输出的结果，该文件可以在右面板下载。

#### **6 运行模板**

选中模型训练节点，在运行选择“运行到此处”将会运行改节点和上游节点。

如果选择“运行该节点”将会只运行当前节点。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/eb55a15c6226af2224f764fc368937b7.png)

模型评估和预测

运行成功的节点会显示绿色打钩图标。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/d2e7606cd24b19651c6c126dc71bb5d1.png)

运行成功的节点

当模型训练运行成功后，对于下游的模型评估和模型预测我们只需要选择“运行该节点”即可。你可以在右面板的查看任意运行成功节点的结果和输出数据。

#### **Keras 图片分类（迁移学习）**

模板ID：3894

我们在ImagNet 预先训练的模型基础上通过迁移学习的方式训练一个可以区分猫和狗图片的模型，数据可以在微软[网站](https://www.microsoft.com/en-us/download/details.aspx?id=54765)下载或从算盘演示模板中的和模型训练相连的上传数据节点下载。当然你也可以通过上传自定义图片集实现其他类型图片分类的应用。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/bd913e2cabaf916ab738150325117ea6.jpg)

猫狗图片分类

Keras 图片分类（迁移学习）模型，上传自定图片，训练两个epoch达到92.3%的验证数据集准确率。此案例建议在配置了GPU加速的机器上运行，因为训练图片分类模型需要消耗较多计算资源，GPU可以通过并行计算加速模型训练。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/0fef39db6f2017f791d030ca70db68d2.png)

图片分类（迁移学习）实例

#### **1 添加输入层**

配置模型输入层的名称和shape，图片在加载模型前会被调整为指定分辨率。如下配置，RGB彩色图片将会被调整为244 x 244 大小。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/86374c0aaf74d4f180d6ef7c29a098a9.png)

添加输入层

#### **2添加特征提取网络**

特征提取网络是已经使用大规模数据数据训练过的深度学习卷积网络，可以作为迁移学习使用。特征提取网络是训练好的ImageNet模型去掉分类层并冻结所有层的结果。此实例中我们选择了轻量级的MobileNetV2网络，相比其他参数更多的ImageNet模型而言，此网络预训练和测速度更快，消耗的计算资源更少。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/4223a9bfa7ce53a27aeef4968a80834e.png)

添加特征提取网络节点

#### **3添加分类网络并构建模型**

特征提取网络输出到Flatten层，将多维度的图片特征张量平铺展开为1维度的张量，Dense全连接层配置为分类。接下来我们上传的数据一共有两种分类（cats和dogs），所以units设为2。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/9c3f394e37ccd79e9ef8fced5c54d32a.png)

添加分类网络

创建模型方式和上一个案例类似。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/b4bc2c558e1380d3a26a37e17def5980.png)

_创建模型_

#### **4添加模型训练节点**

“Keras模型训练文件夹数据”节点可以读取文件夹中的图片数据训练Keras模型。该节点支持加载文件夹压缩的一个zip包。

案例中模型训练后将可以识别2分类（cats 和 dogs），参考压缩包内部文件夹结构如下图。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/ef00f0150f8c0e198b097ce2c8d66826.png)

参考文件夹结构

每个类应包含一个子目录。每个子目录目录树中可以为任何的 PNG、JPG、BMP、PPM 或 TIF 图像，路径中不能有中文，图片名称命名没有其他要求。

```text
data
├── test
│   ├── labelA
│   ├── ...
│   └── labelZ
├── train
│   ├── labelA
│   ├── ...
│   └── labelZ
└── validation
    ├── labelA
    ├── ...
    └── labelZ
```

train，test，validation分别代表训练、测试和评估集。test 和 validation 文件夹可以没有。更多细节可以参考Keras [flow\_from\_directory](https://keras.io/preprocessing/image/#flow_from_directory)文档。

参考下图配置训练节点。epochs决定模型遍历训练集数据的轮次，训练轮次数越多往往最终准确率较高但也可能出现过拟合情况。用户也可根据GPU显存大小配置适当调高batchSize以加快训练速度或接受默认配置。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/62a86a3c66be0ac5bfc2c66cca26f96b.png)

参考文件夹结构

#### **5数据上传节点**

如图配置数据上传节点并上传zip文件。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/40276cc38ba0864380d31e29dd7a43a0.png)

数据上传节点

#### **6模型图片分类\(预测\)**

模型训练节点训练结束后会输出模型权值文件可供接下来的分类预测节点加载。

脱出Keras模型图片分类节点。按下图连接并配置该节点。classLabels可选配置项，如果提供了将会在预测标签中显示对应的分类标签。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/523cd1b32e1d46a2288246accc4b0fb1.png)

模型图片分类\(预测\)节点配置

在新添加的数据上传节点上传一张图片文件（cat或dog的图片），在上传前请将文件命名为file，去掉文件扩展名。

#### **7运行模板**

如果在“Keras模型图片分类” 节点选择运行到此节点，将会运行模板中所有节点。在“Keras模型训练文件夹数据”的执行日志可以看到Keras模型训练的进度和最终loss和准确度。

“Keras模型图片分类” 节点的查看结果可以看到模型对上传图片的预测结果。如下图显示的模型认为上传的图片属于cat的概率是99.8%。

![](https://raw.githubusercontent.com/xuelang-group/suanpan-docs/master/pictures/deep_learning/bead4d24fd0db4919873b8c27ff5a524.png)

模型图片分类\(预测\)节点结果

